{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:04:06.915262Z",
     "start_time": "2020-11-06T08:04:06.052249Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T11:06:49.265748Z",
     "start_time": "2020-11-06T11:06:49.260094Z"
    }
   },
   "outputs": [],
   "source": [
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.datasets import qg_jets\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:04:51.371586Z",
     "start_time": "2020-11-06T08:04:51.368127Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing and mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:08:08.563653Z",
     "start_time": "2020-11-06T08:08:07.622722Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Data\n",
    "\"\"\"\n",
    "X_sig_path = \"training_data/X_sig.npy\"\n",
    "y_sig_path = \"training_data/y_sig.npy\"\n",
    "X_sb_path = \"training_data/X_sb.npy\"\n",
    "y_sb_path = \"training_data/y_sb.npy\"\n",
    "X_bgsig_path = \"training_data/X_bgsig.npy\"\n",
    "y_bgsig_path = \"training_data/y_bgsig.npy\"\n",
    "X_sig = np.load(X_sig_path)\n",
    "y_sig = np.load(y_sig_path)\n",
    "X_sb = np.load(X_sb_path)\n",
    "y_sb = np.load(y_sb_path)\n",
    "X_bgsig = np.load(X_bgsig_path)\n",
    "y_bgsig = np.load(y_bgsig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T10:34:53.086648Z",
     "start_time": "2020-11-06T10:34:53.057519Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prep_and_shufflesplit_data(anomaly_ratio, size_each = 76000, shuffle_seed = 69,\n",
    "                               train = 0.8, val = 0.2, test_size_each = 5000, special_test = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Pre-Data Selection\n",
    "    \"\"\"\n",
    "        \n",
    "    #how much bg and signal data to take?\n",
    "    \n",
    "    anom_size = round(anomaly_ratio * size_each)\n",
    "    bgsig_size = size_each - anom_size\n",
    "    \n",
    "    # make sure we have enough data.\n",
    "    assert (size_each <= X_sb.shape[0])\n",
    "    assert (anom_size + test_size_each <= X_sig.shape[0])\n",
    "    assert (bgsig_size + test_size_each <= X_bgsig.shape[0])\n",
    "    \n",
    "    \"\"\"\n",
    "    Data Selection\n",
    "    \"\"\"\n",
    "    \n",
    "    # select sideband datapoints\n",
    "    this_X_sb = X_sb[:size_each]\n",
    "    this_y_sb = np.zeros(size_each)\n",
    "    \n",
    "    # select bgsig datapoints\n",
    "    this_X_bgsig = X_bgsig[:bgsig_size]\n",
    "    this_y_bgsig = np.ones(bgsig_size)\n",
    "    \n",
    "    # select anomaly datapoints\n",
    "    this_X_sig = X_sig[:anom_size]\n",
    "    this_y_sig = np.ones(anom_size)\n",
    "    \n",
    "    \"\"\"\n",
    "    Shuffle + Train-Val-Test Split (not test set)\n",
    "    \"\"\"\n",
    "    # Combine all 3 data sets\n",
    "    this_X = np.concatenate([this_X_sb, this_X_bgsig, this_X_sig])\n",
    "    this_y = np.concatenate([this_y_sb, this_y_bgsig, this_y_sig])\n",
    "    \n",
    "    # Shuffle before we split\n",
    "    this_X, this_y = shuffle(this_X, this_y, random_state = shuffle_seed)\n",
    "    \n",
    "    \n",
    "    (this_X_tr, this_X_v, _,\n",
    "     this_y_tr, this_y_v, _) = data_split(this_X, this_y, val=val, test=0)\n",
    "        \n",
    "    \n",
    "    print('Size of sb:')\n",
    "    print(this_X_sb.shape)\n",
    "    print('Size of bgsig:')\n",
    "    print(this_X_bgsig.shape)\n",
    "    print('Size of sig:')\n",
    "    print(this_X_sig.shape)\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    Get the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    # select the data\n",
    "    this_X_test_P = X_sig[anom_size:anom_size+test_size_each]\n",
    "    this_X_test_N = X_bgsig[bgsig_size:bgsig_size+test_size_each]\n",
    "    \n",
    "    this_y_test_P = np.ones(test_size_each)\n",
    "    this_y_test_N = np.zeros(test_size_each)\n",
    "        \n",
    "    # Shuffle the combination    \n",
    "    this_X_te = np.concatenate([this_X_test_P, this_X_test_N])\n",
    "    this_y_te = np.concatenate([this_y_test_P, this_y_test_N])\n",
    "    \n",
    "    this_X_te, this_y_te = shuffle(this_X_te, this_y_te, random_state = shuffle_seed)\n",
    "#     print('Size of test set:')\n",
    "#     print(this_X_te.shape)\n",
    "#     print('Test set distribution:')\n",
    "#     print(np.unique(this_y_te,return_counts = True))\n",
    "    \n",
    "    \n",
    "    X_train, X_val, X_test, y_train, y_val, y_test \\\n",
    "    = this_X_tr, this_X_v, this_X_te, this_y_tr, this_y_v, this_y_te\n",
    "    \n",
    "    \"\"\"\n",
    "    Data processing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Centre and normalize all the Xs\n",
    "    for x in X_train:\n",
    "        mask = x[:,0] > 0\n",
    "        yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "        x[mask,1:3] -= yphi_avg\n",
    "        x[mask,0] /= x[:,0].sum()\n",
    "    for x in X_val:\n",
    "        mask = x[:,0] > 0\n",
    "        yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "        x[mask,1:3] -= yphi_avg\n",
    "        x[mask,0] /= x[:,0].sum()\n",
    "    for x in X_test:\n",
    "        mask = x[:,0] > 0\n",
    "        yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "        x[mask,1:3] -= yphi_avg\n",
    "        x[mask,0] /= x[:,0].sum()\n",
    "    \n",
    "    # remap PIDs for all the Xs\n",
    "    remap_pids(X_train, pid_i=3)\n",
    "    remap_pids(X_val, pid_i=3)\n",
    "    remap_pids(X_test, pid_i=3)\n",
    "    \n",
    "    # change Y to categorical Matrix\n",
    "    Y_train = to_categorical(y_train, num_classes=2)\n",
    "    Y_val = to_categorical(y_val, num_classes=2)\n",
    "    Y_test = to_categorical(y_test, num_classes=2)\n",
    "    \n",
    "    print('Training set size, distribution:')\n",
    "    print(X_train.shape)\n",
    "    print(np.unique(y_train,return_counts = True))\n",
    "    print('Validations set size, distribution:')\n",
    "    print(X_val.shape)\n",
    "    print(np.unique(y_val,return_counts = True))\n",
    "    print('Test set size, distribution:')\n",
    "    print(X_test.shape)\n",
    "    print(np.unique(y_test,return_counts = True))\n",
    "    \n",
    "    return X_train, X_val, X_test, Y_train,Y_val,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T10:36:52.253723Z",
     "start_time": "2020-11-06T10:36:52.248750Z"
    }
   },
   "outputs": [],
   "source": [
    "Phi_sizes, F_sizes = (20, 20, 20), (20,20,20)\n",
    "num_epoch = 3\n",
    "num_cycles = 3\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T10:36:53.252736Z",
     "start_time": "2020-11-06T10:36:53.242722Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, X_val, X_test, Y_train,Y_val,Y_test):\n",
    "    model = PFN(input_dim=X_train.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "    histories = []\n",
    "    Y_predicts = []\n",
    "    for cycle in range(num_cycles):\n",
    "        print('----')\n",
    "        print('Beginning cycle ' + str(cycle))\n",
    "        history = model.fit(X_train, Y_train,\n",
    "              epochs=num_epoch,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(X_val, Y_val),\n",
    "              verbose=1)\n",
    "        Y_predict = model.predict(X_test)\n",
    "        histories.append(history)\n",
    "        Y_predicts.append(Y_predict)\n",
    "    \n",
    "    return (histories, Y_test, Y_predicts, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T11:19:01.461173Z",
     "start_time": "2020-11-06T11:19:01.444692Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_model(histories, Y_test, Y_predicts):\n",
    "    fine_index = list(range(num_epoch * num_cycles))\n",
    "    rough_index = list(range(num_epoch - 1, num_epoch * num_cycles, num_epoch))\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for h in histories:\n",
    "        curr_train_acc = h.history['acc']\n",
    "        curr_val_acc = h.history['val_acc']\n",
    "        train_acc.extend(curr_train_acc)\n",
    "        val_acc.extend(curr_val_acc)\n",
    "\n",
    "\n",
    "    medians = []\n",
    "    test_acc = []\n",
    "    for Y_pred in Y_predicts:\n",
    "        medians.append(np.median(Y_pred[:,1:]))\n",
    "        curr_acc = accuracy_score(Y_test[:,1:], (Y_pred[:,1:]*2).astype(int))\n",
    "        test_acc.append(curr_acc)\n",
    "\n",
    "    fig = plt.figure(figsize = (8,6))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(fine_index, train_acc, label = 'train_acc', color='tab:blue')\n",
    "    ax.plot(fine_index, val_acc, label = 'val_acc', color='tab:orange')\n",
    "    #ax.plot(rough_index, medians, marker = '.', label = 'median', color = 'green')\n",
    "    ax.plot(rough_index, test_acc, marker = '.',linestyle = ':',label = 'test_acc', color = 'red')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0, num_epoch * num_cycles])\n",
    "\n",
    "    ax.set_title('line plot with data points')\n",
    "\n",
    "    # display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt 1: 25 percent signal.\n",
    "\n",
    "Uses standard data processing params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T11:23:31.359692Z",
     "start_time": "2020-11-06T11:23:31.354590Z"
    }
   },
   "outputs": [],
   "source": [
    "Phi_sizes, F_sizes = (20, 20, 20), (20,20,20)\n",
    "num_epoch = 3\n",
    "num_cycles = 15\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T11:24:03.406392Z",
     "start_time": "2020-11-06T11:23:33.242289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sb:\n",
      "(76000, 282, 4)\n",
      "Size of bgsig:\n",
      "(57000, 282, 4)\n",
      "Size of sig:\n",
      "(19000, 282, 4)\n",
      "Training set size, distribution:\n",
      "(121600, 282, 4)\n",
      "(array([0., 1.]), array([60892, 60708]))\n",
      "Validations set size, distribution:\n",
      "(30400, 282, 4)\n",
      "(array([0., 1.]), array([15108, 15292]))\n",
      "Test set size, distribution:\n",
      "(10000, 282, 4)\n",
      "(array([0., 1.]), array([5000, 5000]))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, Y_train,Y_val,Y_test = prep_and_shufflesplit_data(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T11:25:18.706095Z",
     "start_time": "2020-11-06T11:24:03.408153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 20)     100         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, 20)     0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 20)     420         activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, 20)     0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 20)     420         activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, 20)     0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 20)           0           mask[0][0]                       \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 20)           420         sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 20)           0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           420         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 20)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           420         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 20)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            42          activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,242\n",
      "Trainable params: 2,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "----\n",
      "Beginning cycle 0\n",
      "Train on 121600 samples, validate on 30400 samples\n",
      "Epoch 1/3\n",
      "121600/121600 [==============================] - 19s 153us/step - loss: 0.7505 - acc: 0.5281 - val_loss: 0.6937 - val_acc: 0.5183\n",
      "Epoch 2/3\n",
      "121600/121600 [==============================] - 18s 149us/step - loss: 0.6921 - acc: 0.5118 - val_loss: 0.6932 - val_acc: 0.5030\n",
      "Epoch 3/3\n",
      "121600/121600 [==============================] - 18s 148us/step - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6932 - val_acc: 0.4970\n",
      "----\n",
      "Beginning cycle 1\n",
      "Train on 121600 samples, validate on 30400 samples\n",
      "Epoch 1/3\n",
      "121600/121600 [==============================] - 18s 148us/step - loss: 0.6932 - acc: 0.5012 - val_loss: 0.6931 - val_acc: 0.5030\n",
      "Epoch 2/3\n",
      "  8650/121600 [=>............................] - ETA: 16s - loss: 0.6933 - acc: 0.4980"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-35af8ea5a0c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_predicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-2f8a16d1d363>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X_train, X_val, X_test, Y_train, Y_val, Y_test)\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mY_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/energyflow/archs/archbase.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# do the fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# handle saving at the end, if we weren't already saving throughout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mdefault_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdefault_session\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories, Y_test, Y_predicts, model = train_model(X_train, X_val, X_test, Y_train,Y_val,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T11:25:18.708398Z",
     "start_time": "2020-11-06T11:24:19.541Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model(histories, Y_test, Y_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt 2: 5 percent signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, Y_train,Y_val,Y_test = prep_and_shufflesplit_data(0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
